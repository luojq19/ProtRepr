pretrained_model_dir: logs_ensemble/train_mlp_single_label_NC_deeper_esm1b_for_ensemble__seed_0
data:
  train_data_file: data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt
  test_data_file: data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_test.pt
  # valid_data_file: data/ec/sprot_10_1022_esm1b_t33_ec_above_10_single_label_val.pt
  # test_data_file: data/ec/sprot_10_1022_esm1b_t33_ec_above_10_single_label_test.pt
  original_train_data_file: data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt
  label_file: data/ec/swissprot_ec_list_above_10.json
  label_name: ec
  dataset_type: SingleLabelSequenceDataset

model:
  model_type: MLPModel
  input_dim: 1280
  num_layers: 5
  hidden_dims: [5120, 5120, 2560, 2000]
  out_dim: null
  dropout: 0.5

train:
  seed: 0
  batch_size: 1000
  num_epochs: 10000
  lr: 1.e-4
  weight_decay: 0.0
  patience: 20
  loss: NCLoss
  sup_criterion: CrossEntropyLoss
  lambda1: 0.0
  lambda2: 0.0
  lambda_CE: 1.0
  optimizer: Adam
  start_NC_epoch: 0
  nc1: NC1Loss_v2_cosine
  nc2: NC2Loss
  freeze_encoder: True
  load_pretrained_means: True