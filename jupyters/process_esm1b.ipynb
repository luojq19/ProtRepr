{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccd49cbf16a4a669904b4eec5ecbde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/167108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d39a1bccc84ea39e6e8574b2c06536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e7f0fac39f43068ee8470decc8f8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20889 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "emb_dir = '/work/jiaqi/CLEAN/app/data/esm_data'\n",
    "tags = ['train', 'val', 'test']\n",
    "for tag in tags:\n",
    "    esm2_data = torch.load(f'../data/ec/sprot_10_1022_esm2_t33_ec_above_10_single_label_{tag}.pt')\n",
    "    esm1b_data = {}\n",
    "    for pid in tqdm(esm2_data):\n",
    "        emb = torch.load(os.path.join(emb_dir, f'{pid}.pt'))['mean_representations'][33]\n",
    "        esm1b_data[pid] = {'embedding': emb, 'ec': esm2_data[pid]['ec']}\n",
    "    torch.save(esm1b_data, f'../data/ec/sprot_10_1022_esm1b_t33_ec_above_10_single_label_{tag}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of single label entries: 215439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89021b61e18149b5817d0a0b13dd9ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215439 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 210734\n",
      "number of unique labels: 2134\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "emb_dir = '/work/jiaqi/CLEAN/app/data/esm_data'\n",
    "csv_path = '/work/jiaqi/CLEAN/app/data/split100.csv'\n",
    "df = pd.read_csv(csv_path, sep='\\t')\n",
    "# the column EC number doesn't contain ;\n",
    "df_single_label = df[df['EC number'].str.contains(';') == False]\n",
    "entries, ec_numbers = df_single_label['Entry'].tolist(), df_single_label['EC number'].tolist()\n",
    "ec2occurance = {}\n",
    "for ec in ec_numbers:\n",
    "    if ec in ec2occurance:\n",
    "        ec2occurance[ec] += 1\n",
    "    else:\n",
    "        ec2occurance[ec] = 1\n",
    "data = {}\n",
    "n = len(entries)\n",
    "print(f'number of single label entries: {n}')\n",
    "labels_above_10 = [ec for ec in ec2occurance if ec2occurance[ec] >= 5]\n",
    "labels = set()\n",
    "for i in tqdm(range(n)):\n",
    "    pid = entries[i]\n",
    "    ec = ec_numbers[i]\n",
    "    if ec2occurance[ec] < 5:\n",
    "        continue\n",
    "    labels.add(ec)\n",
    "    emb = torch.load(os.path.join(emb_dir, f'{pid}.pt'))['mean_representations'][33]\n",
    "    data[pid] = {'embedding': emb, 'ec': [ec_numbers[i]]}\n",
    "print(f'data: {len(data)}')\n",
    "torch.save(data, f'../data/ec/CLEAN_split100_esm1b_t33_ec_above_5_single_label.pt')\n",
    "# label_list = list(set(ec_numbers))\n",
    "assert labels == set(labels_above_10)\n",
    "label_list = list(labels)\n",
    "print(f'number of unique labels: {len(label_list)}')\n",
    "with open('../data/ec/CLEAN_split100_ec_above_5_single_label_list.json', 'w') as f:\n",
    "    json.dump(label_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price number of single label entries: 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [00:00<00:00, 7866.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price data: 89\n",
      "new number of single label entries: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:00<00:00, 9464.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data: 247\n",
      "halogenase number of single label entries: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 24286.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halogenase data: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import json, os\n",
    "from tqdm import tqdm\n",
    "test_sets = ['price', 'new', 'halogenase']\n",
    "with open('../data/ec/CLEAN_split100_ec_above_5_single_label_list.json') as f:\n",
    "    label_list = json.load(f)\n",
    "emb_dir = '/work/jiaqi/CLEAN/app/data/esm_data'\n",
    "for test_set in test_sets:\n",
    "    csv_path = f'/work/jiaqi/CLEAN/app/data/datasets/{test_set}.csv'\n",
    "    df = pd.read_csv(csv_path, sep='\\t')\n",
    "    df_single_label = df[df['EC number'].str.contains(';') == False]\n",
    "    entries, ec_numbers = df_single_label['Entry'].tolist(), df_single_label['EC number'].tolist()\n",
    "    test_data = {}\n",
    "    n = len(entries)\n",
    "    print(f'{test_set} number of single label entries: {n}')\n",
    "    for i in tqdm(range(n)):\n",
    "        pid = entries[i]\n",
    "        ec = ec_numbers[i]\n",
    "        if ec not in label_list:\n",
    "            continue\n",
    "        emb = torch.load(os.path.join(emb_dir, f'{pid}.pt'))['mean_representations'][33]\n",
    "        test_data[pid] = {'embedding': emb, 'ec': [ec_numbers[i]]}\n",
    "    print(f'{test_set} data: {len(test_data)}')\n",
    "    torch.save(test_data, f'../data/ec/{test_set}_esm1b_t33_single_label_ec_above_5.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 189660, val: 21074\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "data = torch.load('../data/ec/CLEAN_split100_esm1b_t33_ec_above_5_single_label.pt')\n",
    "pids = list(data.keys())\n",
    "random.shuffle(pids)\n",
    "n = len(pids)\n",
    "train_pids = pids[:int(n*0.9)]\n",
    "val_pids = pids[int(n*0.9):]\n",
    "train_data = {pid: data[pid] for pid in train_pids}\n",
    "val_data = {pid: data[pid] for pid in val_pids}\n",
    "print(f'train: {len(train_data)}, val: {len(val_data)}')\n",
    "torch.save(train_data, '../data/ec/CLEAN_split100_esm1b_t33_ec_above_5_single_label_train.pt')\n",
    "torch.save(val_data, '../data/ec/CLEAN_split100_esm1b_t33_ec_above_5_single_label_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 186126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "emb_dir = '/work/jiaqi/CLEAN/app/data/esm_data'\n",
    "csv_path = '/work/jiaqi/CLEAN/app/data/split100.csv'\n",
    "data_path = '../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_train.pt'\n",
    "val_data_path = '../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_val.pt'\n",
    "data = torch.load(data_path)\n",
    "val_data = torch.load(val_data_path)\n",
    "data.update(val_data)\n",
    "pids = list(data.keys())\n",
    "df = pd.read_csv(csv_path, sep='\\t')\n",
    "# filter rows with Entry in pids\n",
    "df = df[df['Entry'].isin(pids)]\n",
    "assert len(df) == len(pids)\n",
    "print(f'df: {len(df)}')\n",
    "df.to_csv('/work/jiaqi/CLEAN/app/data/split100_ec_above_10_single_label_train_val.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 165445, val: 20681, test: 20681\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "data = torch.load('../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label.pt')\n",
    "pids = list(data.keys())\n",
    "random.shuffle(pids)\n",
    "n = len(pids)\n",
    "train_pids = pids[:int(n * 0.8)]\n",
    "val_pids = pids[int(n * 0.8):int(n * 0.9)]\n",
    "test_pids = pids[int(n * 0.9):]\n",
    "train_data = {pid: data[pid] for pid in train_pids}\n",
    "val_data = {pid: data[pid] for pid in val_pids}\n",
    "test_data = {pid: data[pid] for pid in test_pids}\n",
    "print(f'train: {len(train_data)}, val: {len(val_data)}, test: {len(test_data)}')\n",
    "torch.save(train_data, '../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_train.pt')\n",
    "torch.save(val_data, '../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_val.pt')\n",
    "torch.save(test_data, '../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_test.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean: 206807, sprot: 228551\n",
      "intersection: 205914\n",
      "percentage: 0.9956819643435667 in clean; 0.9009542727881305 in sprot\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "clean_split100_data = torch.load('../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label.pt')\n",
    "sprot_data = torch.load('../data/ec/sprot_10_1022_esm2_t33_ec_above_10.pt')\n",
    "clean_pids = set(clean_split100_data.keys())\n",
    "sprot_pids = set(sprot_data.keys())\n",
    "print(f'clean: {len(clean_pids)}, sprot: {len(sprot_pids)}')\n",
    "intersection = clean_pids.intersection(sprot_pids)\n",
    "print(f'intersection: {len(intersection)}')\n",
    "print(f'percentage: {len(intersection) / len(clean_pids)} in clean; {len(intersection) / len(sprot_pids)} in sprot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas \n",
    "\n",
    "test_data = torch.load('../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_test.pt')\n",
    "test_pids = list(test_data.keys())\n",
    "df = pandas.read_csv('/work/jiaqi/CLEAN/app/data/split100.csv', sep='\\t')\n",
    "df = df[df['Entry'].isin(test_pids)]\n",
    "print(f'test: {len(df)}')\n",
    "df.to_csv('/work/jiaqi/CLEAN/app/data/split100_ec_above_10_single_label_test.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_data = torch.load('../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_train.pt')\n",
    "val_data = torch.load('../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_val.pt')\n",
    "train_data.update(val_data)\n",
    "torch.save(train_data, '../data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_train_val.pt')\n",
    "# python scripts/eval_CLEAN.py configs/eval_long_tail.yml --clean_pred_file /work/jiaqi/CLEAN/app/results/inputs/CLEAN_split100_ec_above_10_single_label_test_maxsep_train.csv --train_data_file data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_train.pt --test_data_file data/ec/CLEAN_split100_esm1b_t33_ec_above_10_single_label_test.pt --label_file data/ec/CLEAN_split100_ec_above_10_single_label_list.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: 208885\n",
      "train_val: 167108, test: 41777\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "all_data = {}\n",
    "for tag in ['train', 'val', 'test']:\n",
    "    data = torch.load(f'../data/ec/sprot_10_1022_esm1b_t33_ec_above_10_single_label_{tag}.pt')\n",
    "    all_data.update(data)\n",
    "print(f'all: {len(all_data)}')\n",
    "torch.save(all_data, '../data/ec/sprot_10_1022_esm1b_t33_ec_above_10_single_label.pt')\n",
    "all_pids = list(all_data.keys())\n",
    "random.shuffle(all_pids)\n",
    "n = len(all_pids)\n",
    "train_val_pids = all_pids[:int(n * 0.8)]\n",
    "test_pids = all_pids[int(n * 0.8):]\n",
    "train_val_data = {pid: all_data[pid] for pid in train_val_pids}\n",
    "test_data = {pid: all_data[pid] for pid in test_pids}\n",
    "print(f'train_val: {len(train_val_data)}, test: {len(test_data)}')\n",
    "torch.save(train_val_data, '../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt')\n",
    "torch.save(test_data, '../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 41777\n",
      "test: 41777\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas \n",
    "\n",
    "test_data = torch.load('../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_test.pt')\n",
    "test_pids = list(test_data.keys())\n",
    "print(f'test: {len(test_pids)}')\n",
    "df = pandas.read_csv('/work/jiaqi/CLEAN/app/data/sprot_10_1022_ec_above_10_single_label_all.csv', sep='\\t')\n",
    "df = df[df['Entry'].isin(test_pids)]\n",
    "print(f'test: {len(df)}')\n",
    "df.to_csv('/work/jiaqi/CLEAN/app/data/sprot_10_1022_ec_above_10_single_label_test_for_ensemble.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val: 167108\n",
      "train_val: 167108\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas \n",
    "\n",
    "train_val_data = torch.load('../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt')\n",
    "train_val_pids = list(train_val_data.keys())\n",
    "print(f'train_val: {len(train_val_pids)}')\n",
    "df = pandas.read_csv('/work/jiaqi/CLEAN/app/data/sprot_10_1022_ec_above_10_single_label_all.csv', sep='\\t')\n",
    "df = df[df['Entry'].isin(train_val_pids)]\n",
    "print(f'train_val: {len(df)}')\n",
    "df.to_csv('/work/jiaqi/CLEAN/app/data/sprot_10_1022_ec_above_10_single_label_train_val_for_ensemble.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'P25152_8' in train_val_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/work/jiaqi/CLEAN/app/data/inputs/sprot_10_1022_ec_above_10_single_label_test_for_ensemble.csv', sep='\\t')\n",
    "entries, seqs = df['Entry'].tolist(), df['Sequence'].tolist()\n",
    "entry_seq_list = [f'>{entries[i]}\\n{seqs[i]}\\n' for i in range(len(entries))]\n",
    "with open('/work/jiaqi/CLEAN/app/data/inputs/sprot_10_1022_ec_above_10_single_label_test_for_ensemble.fasta', 'w') as f:\n",
    "    f.writelines(entry_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val: 167108\n",
      "train: 146219, val: 20889\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "train_val_data = torch.load(f'../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt')\n",
    "print(f'train_val: {len(train_val_data)}')\n",
    "train_val_pids = list(train_val_data.keys())\n",
    "random.shuffle(train_val_pids)\n",
    "train_pids = train_val_pids[:int(len(train_val_pids) * 0.875)]\n",
    "val_pids = train_val_pids[int(len(train_val_pids) * 0.875):]\n",
    "train_data = {pid: train_val_data[pid] for pid in train_pids}\n",
    "val_data = {pid: train_val_data[pid] for pid in val_pids}\n",
    "print(f'train: {len(train_data)}, val: {len(val_data)}')\n",
    "torch.save(train_data, f'../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train.pt')\n",
    "torch.save(val_data, f'../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B9JG24',\n",
       " 'Q49YU4',\n",
       " 'C4ZW44',\n",
       " 'C3LKW3',\n",
       " 'Q8ZWV9',\n",
       " 'B1KJM7',\n",
       " 'Q2SZS9',\n",
       " 'A1KWN7',\n",
       " 'O83433',\n",
       " 'B3Q9V6']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load('../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_test.pt')\n",
    "list(data.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': tensor([-0.0049,  0.1555, -0.0897,  ..., -0.0696, -0.0307,  0.0684]),\n",
       " 'ec': ['1.1.1.25']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['B9JG24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 167108\n",
      "train data: 167458\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pid2emb = torch.load('../data/ec/ensemble/esm1b_t33_single_EC_mutations_train_val.pt')\n",
    "train_data = torch.load('../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt')\n",
    "print(f'train data: {len(train_data)}')\n",
    "for pid, emb in pid2emb.items():\n",
    "    ec = train_data[pid.split('_')[0]]['ec']\n",
    "    train_data[pid] = {'embedding': emb, 'ec': ec}\n",
    "torch.save(train_data, '../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val_with_single_EC_mutations.pt')\n",
    "print(f'train data: {len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 2 3 2 0 4 3 4 0 4 3 3 1 3 2 0 3 4 0 "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(20):\n",
    "    print(random.randint(0, 4), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt for occurance statistics...\n",
      "167108\n",
      "164856\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.train_mlp import get_ec2occurance\n",
    "import pandas as pd\n",
    "\n",
    "data_file = '../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt'\n",
    "label_file  = '../data/ec/swissprot_ec_list_above_10.json'\n",
    "ec2occurance, _ = get_ec2occurance(data_file, label_file, 'ec', 4)\n",
    "df = pd.read_csv('/work/jiaqi/CLEAN/app/data/sprot_10_1022_ec_above_10_single_label_train_val_for_ensemble.csv', sep='\\t')\n",
    "print(len(df))\n",
    "# filter rows with ec2occurance[EC number] >= 10\n",
    "df_filtered = df[df['EC number'].apply(lambda x: ec2occurance[x] >= 10)]\n",
    "print(len(df_filtered))\n",
    "df_filtered.to_csv('/work/jiaqi/CLEAN/app/data/sprot_10_1022_ec_above_10_single_label_train_val_for_ensemble_remove_minor.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ECs: 1410, max: 1750, min: 10\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def get_ec_id_dict(csv_name: str) -> dict:\n",
    "    csv_file = open(csv_name)\n",
    "    csvreader = csv.reader(csv_file, delimiter='\\t')\n",
    "    id_ec = {}\n",
    "    ec_id = {}\n",
    "\n",
    "    for i, rows in enumerate(csvreader):\n",
    "        if i > 0:\n",
    "            id_ec[rows[0]] = rows[1].split(';')\n",
    "            for ec in rows[1].split(';'):\n",
    "                if ec not in ec_id.keys():\n",
    "                    ec_id[ec] = set()\n",
    "                    ec_id[ec].add(rows[0])\n",
    "                else:\n",
    "                    ec_id[ec].add(rows[0])\n",
    "    return id_ec, ec_id\n",
    "\n",
    "id_ec, ec_id = get_ec_id_dict('/work/jiaqi/CLEAN/app/data/sprot_10_1022_ec_above_10_single_label_train_val_for_ensemble_remove_minor.csv')\n",
    "ec_id_lens = [len(ec_id[ec]) for ec in ec_id]\n",
    "print(f'number of ECs: {len(ec_id)}, max: {max(ec_id_lens)}, min: {min(ec_id_lens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python scripts/eval_CLEAN.py configs/eval_long_tail.yml --clean_pred_file /work/jiaqi/CLEAN_original/app/results/inputs/sprot_10_1022_ec_above_10_single_label_test_for_ensemble_maxsep_single_mutate_10_seed_0.csv --train_data_file data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt --test_data_file data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_test.pt --label_file data/ec/swissprot_ec_list_above_10.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt for occurance statistics...\n",
      "class0_10: 510, class10_30: 616\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from scripts.train_mlp import get_ec2occurance\n",
    "import pandas as pd\n",
    "\n",
    "data_file = '../data/ec/ensemble/sprot_10_1022_esm1b_t33_ec_above_10_single_label_train_val.pt'\n",
    "label_file  = '../data/ec/swissprot_ec_list_above_10.json'\n",
    "ec2occurance, _ = get_ec2occurance(data_file, label_file, 'ec', 4)\n",
    "\n",
    "class0_10 = [ec for ec in ec2occurance if ec2occurance[ec] < 10]\n",
    "class10_30 = [ec for ec in ec2occurance if ec2occurance[ec] >= 10 and ec2occurance[ec] < 30]\n",
    "print(f'class0_10: {len(class0_10)}, class10_30: {len(class10_30)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9309685612788631"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(510 * 0.8831 + 616 * 0.9706) / 1126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9277154529307283"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(510 * 0.8886 + 616 * 0.9601) / 1126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
